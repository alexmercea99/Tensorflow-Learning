{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transfer Learning with TensorFlow\r\n",
    "# Feature Extraction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transfer Learning is leveraging a working model's existing architecture and learned patterns for our own problem.\r\n",
    "\r\n",
    "There are two main benefits:\r\n",
    "1. Can leverage an existing neural network architecture proven to work on problems similar to our own.\r\n",
    "2. Can leverage a working neuratl network architecture which has already learned patterns on similar data to our own, then we can adapt those patterns to our own data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Downloading Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "import os\r\n",
    "\r\n",
    "for dirpath, dirname, filenames in os.walk(\"10_food_classes_10_percent\"):\r\n",
    "    print( f\" In {dirpath}, directories {len(dirname)}, and images {len(filenames)}\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " In 10_food_classes_10_percent, directories 2, and images 0\n",
      " In 10_food_classes_10_percent\\test, directories 10, and images 0\n",
      " In 10_food_classes_10_percent\\test\\chicken_curry, directories 0, and images 250\n",
      " In 10_food_classes_10_percent\\test\\chicken_wings, directories 0, and images 250\n",
      " In 10_food_classes_10_percent\\test\\fried_rice, directories 0, and images 250\n",
      " In 10_food_classes_10_percent\\test\\grilled_salmon, directories 0, and images 250\n",
      " In 10_food_classes_10_percent\\test\\hamburger, directories 0, and images 250\n",
      " In 10_food_classes_10_percent\\test\\ice_cream, directories 0, and images 250\n",
      " In 10_food_classes_10_percent\\test\\pizza, directories 0, and images 250\n",
      " In 10_food_classes_10_percent\\test\\ramen, directories 0, and images 250\n",
      " In 10_food_classes_10_percent\\test\\steak, directories 0, and images 250\n",
      " In 10_food_classes_10_percent\\test\\sushi, directories 0, and images 250\n",
      " In 10_food_classes_10_percent\\train, directories 10, and images 0\n",
      " In 10_food_classes_10_percent\\train\\chicken_curry, directories 0, and images 75\n",
      " In 10_food_classes_10_percent\\train\\chicken_wings, directories 0, and images 75\n",
      " In 10_food_classes_10_percent\\train\\fried_rice, directories 0, and images 75\n",
      " In 10_food_classes_10_percent\\train\\grilled_salmon, directories 0, and images 75\n",
      " In 10_food_classes_10_percent\\train\\hamburger, directories 0, and images 75\n",
      " In 10_food_classes_10_percent\\train\\ice_cream, directories 0, and images 75\n",
      " In 10_food_classes_10_percent\\train\\pizza, directories 0, and images 75\n",
      " In 10_food_classes_10_percent\\train\\ramen, directories 0, and images 75\n",
      " In 10_food_classes_10_percent\\train\\steak, directories 0, and images 75\n",
      " In 10_food_classes_10_percent\\train\\sushi, directories 0, and images 75\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create data loaders (preparing the data)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
    "\r\n",
    "IMAGE_SHAPE = (224, 224)\r\n",
    "BATCH_SIZE = 32\r\n",
    "\r\n",
    "train_dir = \"10_food_classes_10_percent/train\"\r\n",
    "test_dir = \"10_food_classes_10_percent/test\"\r\n",
    "\r\n",
    "train_datagen = ImageDataGenerator(\r\n",
    "        rescale=1./255,\r\n",
    "        shear_range=0.2,\r\n",
    "        zoom_range=0.2,\r\n",
    "        horizontal_flip=True)\r\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\r\n",
    "\r\n",
    "train_generator = train_datagen.flow_from_directory(\r\n",
    "        train_dir,\r\n",
    "        target_size=IMAGE_SHAPE,\r\n",
    "        batch_size=BATCH_SIZE,\r\n",
    "        class_mode='categorical')\r\n",
    "test_generator = test_datagen.flow_from_directory(\r\n",
    "        test_dir,\r\n",
    "        target_size=IMAGE_SHAPE,\r\n",
    "        batch_size=BATCH_SIZE,\r\n",
    "        class_mode='categorical')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 750 images belonging to 10 classes.\n",
      "Found 2500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setting up **callbacks** (things to run whilst our model trains)\r\n",
    "\r\n",
    "**Callbacks** are extra functionality you can add to your model to be performed during or after training.\r\n",
    "\r\n",
    "Some of the most popular **callbacks**:\r\n",
    "* Tracking experiments with the **TensorBoard** callback\r\n",
    "* Model checkpoint with the **ModelCheckpoint** callback\r\n",
    "* Stopping a model from training (before it trains too long and overfits) with the **EarlyStopping** callback"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "# Create TensorBoard callback\r\n",
    "import datetime\r\n",
    "\r\n",
    "\r\n",
    "def create_tensorboard_callback(dir_name, experiment_name):\r\n",
    "    log_dir = (\r\n",
    "        dir_name\r\n",
    "        + \"/\"\r\n",
    "        + experiment_name\r\n",
    "        + \"/\"\r\n",
    "        + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
    "    )\r\n",
    "\r\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\r\n",
    "    print(f\"Saving TensorBoard log files to: {log_dir}\")\r\n",
    "    return tensorboard_callback\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating models using TensorFlow Hub"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Access pretrained models on: https://tfhub.dev/"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "# Compare 2 models\r\n",
    "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\"\r\n",
    "\r\n",
    "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "import tensorflow as tf\r\n",
    "import tensorflow_hub as hub\r\n",
    "from tensorflow.keras import layers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "def create_model(model_url, num_classes=10):\r\n",
    "    \"\"\"Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        model_url (str): The URL of the model\r\n",
    "        num_classes (int, optional): The number of classes in the dataset. Defaults to 10.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        An uncompiled Keras Sequential model with model_url as feature extractor layer\r\n",
    "        and Dense output layer with num_classes output neurons.\r\n",
    "    \"\"\"\r\n",
    "    feature_extractor_layer = hub.KerasLayer(\r\n",
    "        model_url,\r\n",
    "        trainable=False,\r\n",
    "        name=\"feature-extractor-layer\",\r\n",
    "        input_shape=(IMAGE_SHAPE + (3,)),\r\n",
    "    )\r\n",
    "\r\n",
    "    model = tf.keras.Sequential()\r\n",
    "    model.add(feature_extractor_layer)\r\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output-layer\"))\r\n",
    "\r\n",
    "    return model\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating and testing ResNet TensorFlow Hub Feature Extraction model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "# Create Resnet model\r\n",
    "resnet_model = create_model(resnet_url, num_classes=train_generator.num_classes)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "resnet_model.compile(\r\n",
    "    loss=\"categorical_crossentropy\",\r\n",
    "    optimizer=tf.keras.optimizers.Adam(),\r\n",
    "    metrics=[\"accuracy\"],\r\n",
    ")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "resnet_history = resnet_model.fit(\r\n",
    "    train_generator,\r\n",
    "    batch_size=32,\r\n",
    "    epochs=20,\r\n",
    "    steps_per_epoch=len(train_generator),\r\n",
    "    callbacks=[\r\n",
    "        create_tensorboard_callback(\r\n",
    "            dir_name=\"tensorflow_hub\", experiment_name=\"Resnet50V2\"\r\n",
    "        )\r\n",
    "    ],\r\n",
    "    verbose=1,\r\n",
    "    validation_data=test_generator,\r\n",
    "    validation_steps=len(test_generator),\r\n",
    ")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving TensorBoard log files to: tensorflow_hub/Resnet50V2/20210812-122752\n",
      "Epoch 1/20\n",
      "24/24 [==============================] - 26s 904ms/step - loss: 2.0437 - accuracy: 0.3320 - val_loss: 1.2949 - val_accuracy: 0.5764\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 19s 814ms/step - loss: 1.0751 - accuracy: 0.6453 - val_loss: 0.8542 - val_accuracy: 0.7340\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 19s 823ms/step - loss: 0.7547 - accuracy: 0.7707 - val_loss: 0.7802 - val_accuracy: 0.7480\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 19s 817ms/step - loss: 0.6248 - accuracy: 0.8120 - val_loss: 0.7111 - val_accuracy: 0.7720\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 19s 809ms/step - loss: 0.5214 - accuracy: 0.8493 - val_loss: 0.6681 - val_accuracy: 0.7780\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 19s 808ms/step - loss: 0.4727 - accuracy: 0.8613 - val_loss: 0.6455 - val_accuracy: 0.7844\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 20s 828ms/step - loss: 0.4032 - accuracy: 0.8960 - val_loss: 0.6280 - val_accuracy: 0.7896\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 19s 804ms/step - loss: 0.3796 - accuracy: 0.9080 - val_loss: 0.6243 - val_accuracy: 0.7912\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 19s 784ms/step - loss: 0.3328 - accuracy: 0.9120 - val_loss: 0.6202 - val_accuracy: 0.7928\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 18s 764ms/step - loss: 0.2960 - accuracy: 0.9280 - val_loss: 0.6128 - val_accuracy: 0.7924\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 18s 776ms/step - loss: 0.2828 - accuracy: 0.9347 - val_loss: 0.6255 - val_accuracy: 0.7944\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 19s 815ms/step - loss: 0.2496 - accuracy: 0.9453 - val_loss: 0.5995 - val_accuracy: 0.7972\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 19s 787ms/step - loss: 0.2476 - accuracy: 0.9453 - val_loss: 0.6083 - val_accuracy: 0.7900\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 18s 758ms/step - loss: 0.2210 - accuracy: 0.9533 - val_loss: 0.6037 - val_accuracy: 0.7896\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 18s 781ms/step - loss: 0.1912 - accuracy: 0.9640 - val_loss: 0.6029 - val_accuracy: 0.7992\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 18s 760ms/step - loss: 0.1843 - accuracy: 0.9653 - val_loss: 0.6169 - val_accuracy: 0.7916\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 18s 769ms/step - loss: 0.1828 - accuracy: 0.9653 - val_loss: 0.6034 - val_accuracy: 0.8008\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 18s 781ms/step - loss: 0.1577 - accuracy: 0.9733 - val_loss: 0.6086 - val_accuracy: 0.7972\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 18s 766ms/step - loss: 0.1542 - accuracy: 0.9733 - val_loss: 0.5992 - val_accuracy: 0.8012\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 18s 773ms/step - loss: 0.1361 - accuracy: 0.9840 - val_loss: 0.6061 - val_accuracy: 0.7952\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "resnet_model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "feature-extractor-layer (Ker (None, 2048)              23564800  \n",
      "_________________________________________________________________\n",
      "output-layer (Dense)         (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 23,585,290\n",
      "Trainable params: 20,490\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "def plot_loss_and_acc(model_name):\r\n",
    "    plt.plot(model_name.history['loss'])\r\n",
    "    plt.plot(model_name.history['val_loss'])\r\n",
    "    plt.xlabel(\"Epochs\")\r\n",
    "    plt.ylabel(\"Loss\")\r\n",
    "    plt.legend([\"loss\", \"val_loss\"])\r\n",
    "    plt.title(\"Loss\")\r\n",
    "\r\n",
    "    plt.figure()\r\n",
    "    plt.plot(model_name.history['accuracy'])\r\n",
    "    plt.plot(model_name.history['val_accuracy'])\r\n",
    "    plt.xlabel(\"Epochs\")\r\n",
    "    plt.ylabel(\"Accuracy\")\r\n",
    "    plt.legend([\"accuracy\", \"val_accuracy\"])\r\n",
    "    plt.title(\"Accuracy\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "plot_loss_and_acc(resnet_history)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'resnet_history' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2784/3047867930.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_loss_and_acc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresnet_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'resnet_history' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating and testing EfficientNet TensorFlow Hub Feature Extraction model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "efficientnet_model = create_model(efficientnet_url, num_classes=train_generator.num_classes)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "efficientnet_model.compile(\r\n",
    "    loss=\"categorical_crossentropy\",\r\n",
    "    optimizer=tf.keras.optimizers.Adam(),\r\n",
    "    metrics=[\"accuracy\"],\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "efficientnet_history = efficientnet_model.fit(\r\n",
    "    train_generator,\r\n",
    "    batch_size=32,\r\n",
    "    epochs=20,\r\n",
    "    steps_per_epoch=len(train_generator),\r\n",
    "    callbacks=[\r\n",
    "        create_tensorboard_callback(\r\n",
    "            dir_name=\"tensorflow_hub\", experiment_name=\"EfficientNet\"\r\n",
    "        )\r\n",
    "    ],\r\n",
    "    verbose=1,\r\n",
    "    validation_data=test_generator,\r\n",
    "    validation_steps=len(test_generator),\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_loss_and_acc(efficientnet_history)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_loss_and_acc(resnet_history)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('general_env': conda)"
  },
  "interpreter": {
   "hash": "eb1063525ce892d0c528674b1c1740d987616fa50929a74996de9e0faa31f077"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}